{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5839fb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\atulk\\OneDrive\\Desktop\\MAT_PROJ\\.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe1d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=\"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\")\n",
    "prompt = client.pull_prompt(\"teacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51173e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredPrompt(input_variables=['question', 'subject'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'teacher', 'lc_hub_commit_hash': '6e2fc86b4915fc6c18d8ce1c9165240b5a59810e8928ef1214eab6e9cf462205'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['subject'], input_types={}, partial_variables={}, template='You are a teacher and you teach {subject}.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extracts the answer', 'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'The answer from the LLM to the user'}}, 'required': ['answer'], 'additionalProperties': False, 'strict': True}, structured_output_kwargs={})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a920ba6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a teacher and you teach Maths.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Which is the favourite part of the subject?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydrated_prompt = prompt.invoke({\"question\" : \"Which is the favourite part of the subject?\", \"subject\" : \"Maths\"})\n",
    "hydrated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c647c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a teacher and you teach science.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What makes this subjest intereting?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydrated_prompt = prompt.invoke({\"question\" : \"What makes this subjest intereting?\", \"subject\" : \"science\"})\n",
    "hydrated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa008587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a teacher and you teach history.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Why is this subject boring?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydrated_prompt = prompt.invoke({\"question\" : \"Why is this subject boring?\", \"subject\" : \"history\"})\n",
    "hydrated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a12650e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CQ29npZCPpM9p0SrD7vGh9GsCMUfI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Certainly! An algorithm is a step-by-step procedure or set of rules designed to perform a specific task or solve a particular problem. It is a well-defined sequence of instructions that takes an input and produces an output.\\n\\n### Example of an Algorithm: Sorting a List\\n\\nLet's take a simple example of an algorithm: sorting a list of numbers in ascending order using the Bubble Sort algorithm.\\n\\n**Bubble Sort Algorithm:**\\n1. **Start** with a list of numbers.\\n2. **Repeat** the following steps until the list is sorted:\\n   - Compare each pair of adjacent elements in the list.\\n   - If the first element is greater than the second, **swap** them.\\n3. **End** when no swaps are needed, which means the list is sorted.\\n\\n### Example Input\\n\\nLet's say we have the following list of numbers:\\n\\n```\\n[5, 3, 8, 4, 2]\\n```\\n\\n### Step-by-Step Execution of Bubble Sort:\\n\\n1. Compare 5 and 3: Swap → `[3, 5, 8, 4, 2]`\\n2. Compare 5 and 8: No swap → `[3, 5, 8, 4, 2]`\\n3. Compare 8 and 4: Swap → `[3, 5, 4, 8, 2]`\\n4. Compare 8 and 2: Swap → `[3, 5, 4, 2, 8]`\\n\\nAfter the first pass, the largest number (8) is in its correct position.\\n\\nNow, we perform the process again on the first four numbers:\\n\\n1. Compare 3 and 5: No swap → `[3, 5, 4, 2, 8]`\\n2. Compare 5 and 4: Swap → `[3, 4, 5, 2, 8]`\\n3. Compare 5 and 2: Swap → `[3, 4, 2, 5, 8]`\\n\\nContinue this process until no swaps are needed. Eventually, the entire list will be sorted:\\n\\n**Final Sorted List:**\\n\\n```\\n[2, 3, 4, 5, 8]\\n```\\n\\n### Summary\\n\\nThe algorithm systematically processes the list and makes the necessary comparisons and swaps to sort the numbers. This example illustrates the fundamental concept of an algorithm: a clearly-defined set of steps to achieve a specific purpose—in this case, sorting a list of numbers.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760320855, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=512, prompt_tokens=32, total_tokens=544, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "592600d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atulk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\decoder.py:345: UserWarning: WARNING! extra_headers is not default parameter.\n",
      "                extra_headers was transferred to model_kwargs.\n",
      "                Please confirm that extra_headers is what you intended.\n",
      "  obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n"
     ]
    }
   ],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=\"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\")\n",
    "prompt = client.pull_prompt(\"teacher\", include_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "128e4a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredPrompt(input_variables=['question', 'subject'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'teacher', 'lc_hub_commit_hash': '6e2fc86b4915fc6c18d8ce1c9165240b5a59810e8928ef1214eab6e9cf462205'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['subject'], input_types={}, partial_variables={}, template='You are a teacher and you teach {subject}.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extracts the answer', 'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'The answer from the LLM to the user'}}, 'required': ['answer'], 'additionalProperties': False, 'strict': True}, structured_output_kwargs={})\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001E0202B9220>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E020183850>, root_client=<openai.OpenAI object at 0x000001E0202B9040>, root_async_client=<openai.AsyncOpenAI object at 0x000001E020183550>, model_name='gpt-4o-mini', model_kwargs={'extra_headers': {}}, openai_api_key=SecretStr('**********'), top_p=1.0), kwargs={'response_format': {'type': 'json_schema', 'json_schema': {'name': 'answer', 'description': 'Extracts the answer', 'strict': True, 'schema': {'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'The answer from the LLM to the user'}}, 'required': ['answer'], 'additionalProperties': False, 'strict': True}}}, 'ls_structured_output_format': {'kwargs': {'method': 'json_schema', 'strict': None}, 'schema': {'type': 'function', 'function': {'name': 'answer', 'description': 'Extracts the answer', 'parameters': {'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'The answer from the LLM to the user'}}, 'required': ['answer'], 'additionalProperties': False, 'strict': True}}}}}, config={}, config_factories=[])\n",
       "| JsonOutputParser()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40e957b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Science is interesting because it helps us understand the world around us, sparks curiosity, and drives innovation. It allows us to explore complex concepts, discover new frontiers, and comprehend the principles that govern natural phenomena.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\" : \"What makes this subject intereting?\", \"subject\" : \"science\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e099c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=\"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\")\n",
    "prompt = client.pull_prompt(\"teacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "167662f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CQ5L5iKbui0yDuVCmDIJsf4DAuOT3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='In 2500 AD, mathematics education has continued to evolve, but some core topics remain relevant for students at various levels, including those studying matrices. Here are some common topics related to matrices that students typically learn today:\\n\\n1. **Introduction to Matrices:**\\n   - Definition and terminology (rows, columns, elements)\\n   - Types of matrices (square, rectangular, zero matrix, identity matrix)\\n\\n2. **Matrix Operations:**\\n   - Addition and subtraction of matrices\\n   - Scalar multiplication\\n   - Matrix multiplication\\n\\n3. **Determinants:**\\n   - Definition and calculation of determinants for 2x2 and 3x3 matrices\\n   - Properties of determinants\\n   - Applications of determinants in solving systems of equations\\n\\n4. **Inverse of a Matrix:**\\n   - Definition of the inverse matrix\\n   - Methods for finding the inverse (adjoint method, row reduction)\\n   - Applications of the inverse in solving linear equations\\n\\n5. **Linear Equations and Systems:**\\n   - Representing and solving systems of linear equations using matrices\\n   - Gaussian elimination and Gauss-Jordan elimination methods\\n\\n6. **Eigenvalues and Eigenvectors:**\\n   - Definition of eigenvalues and eigenvectors\\n   - Characteristic polynomial and how to find eigenvalues\\n   - Applications in various fields like physics and engineering\\n\\n7. **Matrix Factorization:**\\n   - LU decomposition\\n   - QR factorization\\n   - Singular value decomposition (SVD) and its applications in data analysis\\n\\n8. **Applications of Matrices:**\\n   - Use of matrices in computer graphics, data science, and machine learning\\n   - Understanding transformations in space\\n   - Applications in network theory and systems analysis\\n\\n9. **Advanced Topics (for higher-level students):**\\n   - Functions of matrices\\n   - Matrix differential equations\\n   - Nonlinear transformations and their representations\\n\\n10. **Integration with Technology:**\\n    - Use of software tools and programming languages for matrix calculations and visualizations (e.g., MATLAB, Python, or similar systems in 2500 AD)\\n\\nThese topics provide a comprehensive foundation in matrix theory and its applications, preparing students for further studies in mathematics, science, engineering, and technology.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760333087, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=449, prompt_tokens=45, total_tokens=494, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "hydrated_prompt = prompt.invoke({\"question\": \"What are the common topis of this subject for a matrix student now a days?\", \"subject\": \"maths\"})\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d39d432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/science-rag-prompt/5475a768?organizationId=0262bc87-4e7f-4047-82e4-1316f23416b0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "science_prompt = \"\"\"You are a highly knowledgeable Science Assistant specializing in physics, chemistry, and biology.\n",
    "Use the following pieces of retrieved scientific context to answer the latest question in the conversation concisely and accurately.\n",
    "Ensure your answers maintain scientific rigor and clarity.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "science_prompt_template = ChatPromptTemplate.from_template(science_prompt)\n",
    "client.push_prompt(\"science-rag-prompt\", object=science_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b82bb7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/science-rag-prompt/07540811?organizationId=0262bc87-4e7f-4047-82e4-1316f23416b0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "client = Client()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "science_prompt = \"\"\"You are a highly knowledgeable Science Assistant specializing in physics, chemistry, and biology.\n",
    "Use the following pieces of retrieved scientific context to answer the latest question in the conversation concisely and accurately.\n",
    "Ensure your answers maintain scientific rigor and clarity.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "science_prompt_template = ChatPromptTemplate.from_template(science_prompt)\n",
    "chain = science_prompt_template | model\n",
    "client.push_prompt(\"science-rag-prompt\", object= chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
